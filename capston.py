# -*- coding: utf-8 -*-
"""Capston.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GVYcpUCqIKd1GpLWv0Jfufs-uEOgJSSG
"""

import os
import requests
import zipfile

os.getcwd()

import numpy as np
import os
import shutil
import seaborn as sns
import matplotlib.pyplot as plt
import tqdm
import tqdm as tqdm
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

# Corrected imports for TensorFlow 2.x
# The first few lines from the previous images are assumed to be correct.
# ...
from itertools import product
from sklearn.metrics import confusion_matrix
from sklearn.utils.class_weight import compute_class_weight

# The core Keras imports are now from the main `tensorflow.keras` namespace
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint

# The `backend as K` import is also now from `tensorflow.keras.backend`
from tensorflow.keras import backend as K

from google.colab import drive
drive.mount("/content/drive")

os.getcwd()

os.listdir()

!ls "/content/drive/My Drive/hams/"

import pandas as pd

# Construct the correct path to your CSV file
file_path = "/content/drive/My Drive/hams/HAM10000_metadata.csv"

# Read the CSV file
df = pd.read_csv(file_path)

# Display the first few rows to confirm it loaded correctly
print(df.head())

df.shape

df.info()

df['age'].isna().sum()

# View the rows and columns presentation or the null values on the age column
df[df["age"].isna()]

# Fill the missing value with the mean value of the age
df['age'].fillna(df['age'].mean(), inplace = True)

# Get the information about the dataset
df.info()

import seaborn as sns
import matplotlib.pyplot as plt

# Set Seaborn style
sns.set_style('whitegrid')

# Create the subplot figure
fig, axes = plt.subplots(figsize=(20, 7))

# -------- First subplot: Count of 'dx' --------
ax1 = fig.add_subplot(121)
sns.countplot(
    x='dx',
    hue='dx',  # Fix the FutureWarning
    data=df,
    order=df['dx'].value_counts().index,
    palette='Paired',
    legend=False,  # Suppress legend since hue is same as x
    ax=ax1
)

# Add value labels to bars
for container in ax1.containers:
    ax1.bar_label(container)

# Titles and labels
ax1.set_title('Cell Types Skin Cancer Affected Patients', fontsize=20)
ax1.set_xlabel('Cell Type', fontsize=14)
ax1.set_ylabel('Frequency of Occurrence', fontsize=14)
ax1.tick_params(axis='x', rotation=45, labelsize=12)

# -------- Second subplot: Age distribution --------
ax4 = fig.add_subplot(122)
sns.histplot(df['age'], bins=30, kde=True, color='red', ax=ax4)  # Replaces distplot

ax4.set_title('Age Distribution', fontsize=20)
ax4.set_xlabel('Age', fontsize=14)
ax4.set_ylabel('Density', fontsize=14)

# Display the plots
plt.tight_layout()
plt.show()

df.head()

df_new = df.iloc[:,[2, 6]]

rafa = df_new.groupby("localization").value_counts().reset_index()

# Rename the dataframe column
rafa = rafa.rename(columns={0: "count"})

# Get the data fram for the count of each lesion type, localization
nv = rafa[rafa["dx"] == "nv"]
mel = rafa[rafa["dx"] == "mel"]
bkl = rafa[rafa["dx"] == "bkl"]
vasc = rafa[rafa["dx"] == "vasc"]
bcc = rafa[rafa["dx"] == "bcc"]
akiec = rafa[rafa["dx"] == "akiec"]
dfi = rafa[rafa["dx"] == "df"]

# Getting a sense of the distribution of localization by diagnosis

fig = plt.figure(figsize=(15,10))

ax1 = fig.add_subplot(331)
ax1 = sns.barplot(x = "count",y = "localization",data = nv, palette='husl', order=nv.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax1.containers:
    ax1.bar_label(i,)
ax1.tick_params(axis='y', length=0)
ax1.set_title('nv: Melanocytic nevi(n = 6705)')
plt.tight_layout();

ax2 = fig.add_subplot(332)
ax2 = sns.barplot(x = "count",y = "localization",data = mel, palette='husl', order=mel.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax2.containers:
    ax2.bar_label(i,)
ax2.tick_params(axis='y', length=0)
ax2.set_title('mel: Melanoma (n = 1113)')
plt.tight_layout();

ax3 = fig.add_subplot(333)
ax3 = sns.barplot(x = "count",y = "localization",data = dfi, palette='husl', order=dfi.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax3.containers:
    ax3.bar_label(i,)
ax3.tick_params(axis='y', length=0)
ax3.set_title('df: Dermatofibroma (n = 115)')
plt.tight_layout();


ax4 = fig.add_subplot(334)
ax4 = sns.barplot(x = "count",y = "localization",data = akiec, palette='husl', order=akiec.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax4.containers:
    ax4.bar_label(i,)
ax4.tick_params(axis='y', length=0)
ax4.set_title('Actinic Keratoses (n = 327)')
plt.tight_layout();

ax5 = fig.add_subplot(335)
ax5 = sns.barplot(x = "count",y = "localization",data = bkl, palette='husl', order= bkl.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax5.containers:
    ax5.bar_label(i,)
ax5.tick_params(axis='y', length=0)
ax5.set_title('bkl: Benign Keratoses (n = 1099)')
plt.tight_layout();

ax6 = fig.add_subplot(336)
ax6 = sns.barplot(x = "count",y = "localization",data = vasc, palette='husl', order= vasc.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax6.containers:
    ax6.bar_label(i,)
ax6.tick_params(axis='y', length=0)
ax6.set_title('vasc: Vascular Lesion (n = 142)')
plt.tight_layout();

ax7 = fig.add_subplot(338)
ax7 = sns.barplot(x = "count",y = "localization",data = bcc, palette='husl', order= bcc.groupby('localization')['count'].agg('mean').sort_values(ascending=False).index)
for i in ax7.containers:
    ax7.bar_label(i,)
ax7.tick_params(axis='y', length=0)
ax7.set_title('bc: Basal cell Carcinoma (n = 514)')
plt.tight_layout();


plt.tight_layout()
plt.show()

# A plot of the relationship between the age, sex and lesion type
plt.figure(figsize=(20,5))
sns.catplot(y="dx", x="age", hue="sex",kind="box", height = 6, aspect = 2.5,  data=df).set(title='The visualization of the relationship between the type of lesion, age and the patient sex')
plt.show()

mela = df[df["dx"] == "mel"]
mel_fem = mela[mela["sex"] == "female"]
mel_male = mela[mela["sex"] == "male"]
print("Median age of female with Melanoma is ", mel_fem["age"].median())
print("Median age of male with Melanoma is ", mel_male["age"].median())

# Heat Map Representation
skin_local = df.groupby(['localization']).size().sort_values(ascending=False, inplace=False).reset_index()
skin_local.columns = ['localization', 'count']
sort_by = skin_local['localization']

skin_local_age = df.groupby(['age','localization']).size().reset_index()
skin_local_age.columns = ['age', 'localization', 'count']
skin_local_age.sort_values( "count", ascending=False, inplace=True)

def heatmap(df, index,columns,values,vmax,sort_by,Title):
    df_wide = df.pivot(index=index, columns=columns, values=values)
    df_wide = df_wide.reindex(index=sort_by)
    plt.figure(figsize=(22,8))
    ax = sns.heatmap(df_wide, annot=True, fmt='.0f', yticklabels='auto', cmap=sns.color_palette("YlGnBu", as_cmap=True), center=.2,vmin = 0, vmax = vmax,linewidths=.5)
    ax.xaxis.tick_top() # x axis on top
    ax.xaxis.set_label_position('top')
    ax.set_xlabel(columns,fontsize = 14,weight = 'bold')
    ax.set_ylabel(index,fontsize = 14,weight = 'bold')
    ax.set_title(Title,fontsize = 16,weight = 'bold',pad=20)
    plt.show()

heatmap(skin_local_age,'localization', 'age','count', 20,sort_by,'Age and Localization of Skin Lesions')

#Define the lesion names in a list
lesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',
               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',
               'Dermatofibroma']

lesion_img = df.groupby('lesion_id')['image_id']\
               .count()\
               .to_frame()

# Encoding target values
lesion_type_dict = {
    'nv':'Melanocytic Nevi',
    'mel': 'Melanoma',
    'bkl': 'Benign keratosis',
    'bcc': 'Basal cell carcinoma',
    'akiec': 'Actinic keratoses',
    'vasc': 'Vascular lesions',
    'df': 'Dermatofibroma'

}

# Assign a numeric values to our target variables
lesion_ID_dict = {
    'nv': 0,
    'mel': 1,
    'bkl': 2,
    'bcc': 3,
    'akiec': 4,
    'vasc': 5,
    'df': 6
}

# Create new columns named "cell_type" and "lesion_ID" to depict the ecoded target values
df['cell_type'] = df['dx'].map(lesion_type_dict.get)
df['lesion_ID'] = df['dx'].map(lesion_ID_dict.get)

df

# Define the path
path = '/content/drive/MyDrive/hams/all_images'

import glob # Add this line
import os

# Define the path
path = '/content/drive/MyDrive/hams/all_images'

# Reading the Image Path
images_path = {os.path.splitext(os.path.basename(x))[0]:
               x for x in glob.glob('/content/drive/MyDrive/hams/all_images/*.jpg')}

len(images_path)

# Create a column for the path for each image.
df['path'] = df['image_id'].map(images_path.get)

df

# Check for Image duplicate
num_unique_id = df["image_id"].nunique()

# Print the number of unique image_id
print(f"There are {num_unique_id} unique image IDs in the dataset")

# SetThe lesion_ID as y
y = df["lesion_ID"]

# View the first 5 items on the y column
y.head()

#Convert y to a float arrays
y = np.array(y)
print(y.shape)

df["path"].head()

# Define a function that reads and resizes the Images
def get_img(img_path):
  img = cv2.imread(img_path,1)
  img = cv2.resize(img, (224, 224))

  return img

import os
import cv2
import numpy as np
import tqdm
from concurrent.futures import ThreadPoolExecutor

def process_image(img_name):
    img = cv2.imread(img_name, 1)
    if img is not None:
        return cv2.resize(img, (224, 224))
    return None

save_path = "/content/drive/MyDrive/processed_images.npy"

if os.path.exists(save_path):
    print("Loading preprocessed images...")
    x = np.load(save_path, allow_pickle=True)
else:
    print("Processing images with parallel loading...")
    with ThreadPoolExecutor(max_workers=8) as executor:  # use 8 threads
        results = list(tqdm.tqdm(executor.map(process_image, df['path'].values),
                                 total=len(df)))
    x = [img for img in results if img is not None]
    np.save(save_path, np.array(x))
    print("Images processed and saved to Google Drive!")

y = df["lesion_ID"].values
y = np.array(y)
print(f"Labels shape: {y.shape}")
print(f"Unique classes: {np.unique(y)}")
print(f"Class distribution before balancing: {np.bincount(y)}")

# === Augment per-class to reach TARGET_COUNT images, saving to disk (memory-safe) ===
import os
import math
from collections import Counter
from tqdm import tqdm
import numpy as np
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# --- CONFIGURE ---
TARGET_COUNT = 1500
OUT_ROOT = "/content/drive/MyDrive/augmented_dataset"   # <-- change if you want another folder
IMG_SIZE = (224, 224)   # adjust to your model size
SAVE_FORMAT = "png"     # 'png' smaller lossless, 'jpg' also ok
RESCALE_TO_0_255 = True # set True if your images currently float in [0,1]; False if already 0-255 uint8

# ensure df has 'path' and 'lesion_ID' columns
# df['path'] should point to image file paths (absolute or relative to current runtime)
assert 'path' in df.columns and 'lesion_ID' in df.columns, "df must contain 'path' and 'lesion_ID'"

# --- make output dirs ---
os.makedirs(OUT_ROOT, exist_ok=True)
class_ids = sorted(df['lesion_ID'].unique())  # e.g. [0,1,2,3,4,5,6]
for cls in class_ids:
    os.makedirs(os.path.join(OUT_ROOT, str(int(cls))), exist_ok=True)

# --- save original images into class folders (if not already present) ---
print("Saving original images into per-class folders (skips existing files)...")
for i, row in tqdm(df.iterrows(), total=len(df)):
    src = row['path']
    cls = int(row['lesion_ID'])
    dst_dir = os.path.join(OUT_ROOT, str(cls))
    # Compose a deterministic filename
    base = os.path.splitext(os.path.basename(src))[0]
    dst_path = os.path.join(dst_dir, f"orig_{base}.{SAVE_FORMAT}")
    if os.path.exists(dst_path):
        continue
    try:
        img = Image.open(src).convert("RGB")
        if IMG_SIZE is not None:
            img = img.resize(IMG_SIZE)
        if RESCALE_TO_0_255:
            # if image might be float in [0,1], convert; usually PIL gives 0-255 already
            img = img
        img.save(dst_path, format=SAVE_FORMAT.upper())
    except Exception as e:
        # print and continue if some images fail
        print(f"Failed to save {src}: {e}")
        continue

# --- check current counts ---
def class_counts(root):
    counts = {}
    for cls in class_ids:
        cls_dir = os.path.join(root, str(int(cls)))
        counts[cls] = len([f for f in os.listdir(cls_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))])
    return counts

counts = class_counts(OUT_ROOT)
print("Counts after saving originals:", counts)

# --- set up augmentation generator ---
datagen = ImageDataGenerator(
    rotation_range=25,
    width_shift_range=0.12,
    height_shift_range=0.12,
    shear_range=0.12,
    zoom_range=0.12,
    horizontal_flip=True,
    brightness_range=(0.85, 1.15),
    fill_mode='nearest'
)

# To make generator, we will create a small array of images for each class,
# but we will not keep large arrays for all classes simultaneously.
# We'll loop through classes and create a per-class generator that saves images to disk.

print("\nGenerating augmentations to reach target per-class counts...")
for cls in class_ids:
    cls_dir = os.path.join(OUT_ROOT, str(int(cls)))
    current = len([f for f in os.listdir(cls_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))])
    needed = TARGET_COUNT - current
    if needed <= 0:
        print(f"Class {cls}: already {current} images (>= {TARGET_COUNT}) â€” skipping augmentation.")
        continue

    print(f"Class {cls}: {current} images, generating {needed} more to reach {TARGET_COUNT} ...")
    # Load all images for this class (this is per-class only, usually small)
    file_list = [os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]
    if len(file_list) == 0:
        print(f"  WARNING: no images found for class {cls} - skipping")
        continue

    # Create small numpy array of images for flow; keep dtype uint8 to reduce memory.
    imgs = []
    for p in file_list:
        try:
            im = Image.open(p).convert("RGB").resize(IMG_SIZE)
            arr = np.array(im)  # uint8 HWC
            imgs.append(arr)
        except Exception as e:
            print("  Failed to open:", p, e)

    imgs = np.array(imgs, dtype=np.uint8)
    # create the flow that will save augmented images to cls_dir
    gen = datagen.flow(
        imgs,
        batch_size=1,
        shuffle=True,
        save_to_dir=cls_dir,
        save_prefix=f"aug_{cls}_",
        save_format=SAVE_FORMAT
    )

    # iterate until we've generated 'needed' images
    generated = 0
    # gen yields augmented batches; calling next(gen) will *also* save files because of save_to_dir
    # but for safety count how many new files are created
    initial_files = set(os.listdir(cls_dir))
    pbar = tqdm(total=needed)
    while generated < needed:
        _ = next(gen)  # will save 1 augmented image to disk per call (batch_size=1)
        # check newly added file(s)
        new_files = set(os.listdir(cls_dir)) - initial_files
        added = len([f for f in new_files if f.lower().endswith(('.png','.jpg','.jpeg'))])
        if added > 0:
            generated += added
            initial_files.update(new_files)
            pbar.update(added)
        # safety: break if generator loops too long (shouldn't happen)
        if generated > needed + 10:
            break
    pbar.close()
    print(f"  Done class {cls}: now has {len(os.listdir(cls_dir))} files.")

# final counts
final = class_counts(OUT_ROOT)
print("\nFinal counts per class:", final)
print("Total images in dataset:", sum(final.values()))

import os
import random
import shutil

# --- CONFIG ---
SRC_ROOT = "/content/drive/MyDrive/augmented_dataset" # This should be the root folder containing your class subfolders (e.g., '0', '1', etc.)
TARGET_PER_CLASS = 1500
MOVE_EXCESS_TO = None # Set to a folder path (e.g., 'excess_images') to move the excess instead of deleting; set to None to delete directly.

if MOVE_EXCESS_TO:
    os.makedirs(MOVE_EXCESS_TO, exist_ok=True)

# --- find classes ---
classes = [d for d in os.listdir(SRC_ROOT) if os.path.isdir(os.path.join(SRC_ROOT, d))]
print("Found classes:", classes)

# --- process each class ---
for cls in classes:
    cls_dir = os.path.join(SRC_ROOT, cls)
    files = [f for f in os.listdir(cls_dir) if os.path.isfile(os.path.join(cls_dir, f))]
    n = len(files)

    if n > TARGET_PER_CLASS:
        print(f"Class '{cls}' has {n} images - reducing to {TARGET_PER_CLASS}")

        # Randomly select a sample of images to KEEP
        # The 'random.sample' function is efficient for this
        keep = set(random.sample(files, TARGET_PER_CLASS))

        # Iterate through all files and remove those NOT in the 'keep' set
        for f in files:
            if f not in keep:
                src_path = os.path.join(cls_dir, f)
                if MOVE_EXCESS_TO:
                    dst_path = os.path.join(MOVE_EXCESS_TO, f"{cls}_{f}")
                    shutil.move(src_path, dst_path)
                else:
                    os.remove(src_path)
    else:
        print(f"Class '{cls}': {n} images - OK")

print("\nDone. Final counts may be checked by re-running the class_counts function.")

import os
import matplotlib.pyplot as plt

# Path where your augmented dataset is stored
OUT_ROOT = "/content/drive/MyDrive/augmented_dataset"

# Get class counts
class_counts = {}
for cls in sorted(os.listdir(OUT_ROOT)):
    cls_dir = os.path.join(OUT_ROOT, cls)
    if os.path.isdir(cls_dir):
        count = len([f for f in os.listdir(cls_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))])
        class_counts[cls] = count

# Print counts
print("Number of images per class:")
for cls, count in class_counts.items():
    print(f"Class {cls}: {count}")

# Plot bar chart
plt.figure(figsize=(10,6))
plt.bar(class_counts.keys(), class_counts.values(), color="skyblue", edgecolor="black")
plt.xlabel("Class")
plt.ylabel("Number of Images")
plt.title("Number of Images per Class")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

import tensorflow as tf

# Same folder as your OUT_ROOT path
BATCH_SIZE = 32
IMG_SIZE = (224, 224)

train_ds = tf.keras.utils.image_dataset_from_directory(
    OUT_ROOT,
    labels="inferred",
    label_mode="int",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True
)

# Split Train / Val / Test
TRAIN_SIZE = 0.64
VAL_SIZE = 0.16
TEST_SIZE = 0.20

total_batches = tf.data.experimental.cardinality(train_ds).numpy()
train_batches = int(total_batches * TRAIN_SIZE)
val_batches = int(total_batches * VAL_SIZE)

train_ds_split = train_ds.take(train_batches)
val_ds_split = train_ds.skip(train_batches).take(val_batches)
test_ds_split = train_ds.skip(train_batches + val_batches)

# Define split sizes
TRAIN_SIZE = 0.64
VAL_SIZE = 0.16
TEST_SIZE = 0.20

# Get the total number of batches
total_batches = tf.data.experimental.cardinality(train_ds).numpy()

# Calculate the number of batches for each split
train_batches = int(total_batches * TRAIN_SIZE)
val_batches = int(total_batches * VAL_SIZE)

# Create the new datasets
train_ds_split = train_ds.take(train_batches)
val_ds_split = train_ds.skip(train_batches).take(val_batches)
test_ds_split = train_ds.skip(train_batches + val_batches)

# Print the sizes of the new datasets
print(f"Number of training batches: {tf.data.experimental.cardinality(train_ds_split).numpy()}")
print(f"Number of validation batches: {tf.data.experimental.cardinality(val_ds_split).numpy()}")
print(f"Number of test batches: {tf.data.experimental.cardinality(test_ds_split).numpy()}")

import tensorflow as tf

BATCH_SIZE = 32
IMG_SIZE = (224, 224)

# Load the entire dataset and infer labels from folder structure
full_ds = tf.keras.utils.image_dataset_from_directory(
    OUT_ROOT,
    labels="inferred",
    label_mode="int",
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True
)

TRAIN_SIZE = 0.64
VAL_SIZE = 0.16
TEST_SIZE = 0.20

total_batches = tf.data.experimental.cardinality(full_ds).numpy()
train_batches = int(total_batches * TRAIN_SIZE)
val_batches = int(total_batches * VAL_SIZE)

train_ds_split = full_ds.take(train_batches)
val_ds_split = full_ds.skip(train_batches).take(val_batches)
test_ds_split = full_ds.skip(train_batches + val_batches)

print("Dataset is already split into train_ds_split, val_ds_split, and test_ds_split.")

# ================== IMPORT RESNET50 DEPENDENCIES ==================
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# ================== BUILD RESNET50 MODEL ==================
def build_resnet50_model(input_shape=(224, 224, 3), num_classes=7):
    base_model = ResNet50(weights="imagenet", include_top=False, input_shape=input_shape)
    base_model.trainable = False  # Freeze base layers

    inputs = Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x = GlobalAveragePooling2D()(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    x = Dense(256, activation="relu")(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    outputs = Dense(num_classes, activation="softmax")(x)
    model = Model(inputs, outputs)
    return model, base_model

model, base_model = build_resnet50_model()
model.compile(optimizer=Adam(learning_rate=0.001),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

callbacks = [
    ModelCheckpoint("best_model_frozen.h5", monitor="val_accuracy", save_best_only=True, mode="max", verbose=1),
    EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, min_lr=1e-7, verbose=1)
]

# ================== TRAINING PHASE 1: FROZEN BASE ==================
history_frozen = model.fit(
    train_ds_split,
    validation_data=val_ds_split,
    epochs=25,
    callbacks=callbacks
)

# ================== TRAINING PHASE 2: FINE-TUNING ==================
base_model.trainable = True
for layer in base_model.layers[:-35]:
    layer.trainable = False  # Unfreeze last 35 layers

model.compile(optimizer=Adam(learning_rate=0.0001),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

finetune_callbacks = [
    ModelCheckpoint("best_model_finetuned.h5", monitor="val_accuracy", save_best_only=True, mode="max", verbose=1),
    EarlyStopping(monitor="val_loss", patience=15, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=5, min_lr=1e-8, verbose=1)
]

history_finetune = model.fit(
    train_ds_split,
    validation_data=val_ds_split,
    epochs=35,
    callbacks=finetune_callbacks
)

test_loss, test_accuracy = model.evaluate(test_ds_split, verbose=1)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Get true and predicted labels
y_true = []
y_pred = []

for images, labels in test_ds_split:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Assuming your class names list is called lesion_names
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=lesion_names))

# Confusion matrix plot
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt="d", xticklabels=lesion_names, yticklabels=lesion_names, cmap='Blues')
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.title("Confusion Matrix")
plt.show()

def plot_training_history(history1, history2):
    import matplotlib.pyplot as plt
    plt.figure(figsize=(14, 5))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history1.history['accuracy'], label='Train Accuracy Phase 1')
    plt.plot(history1.history['val_accuracy'], label='Val Accuracy Phase 1')
    plt.plot(history2.history['accuracy'], label='Train Accuracy Phase 2')
    plt.plot(history2.history['val_accuracy'], label='Val Accuracy Phase 2')
    plt.title("Accuracy over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(history1.history['loss'], label='Train Loss Phase 1')
    plt.plot(history1.history['val_loss'], label='Val Loss Phase 1')
    plt.plot(history2.history['loss'], label='Train Loss Phase 2')
    plt.plot(history2.history['val_loss'], label='Val Loss Phase 2')
    plt.title("Loss over Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)

    plt.show()

# Call with your saved history objects
plot_training_history(history_frozen, history_finetune)

def visualize_predictions(model, dataset, class_names, num_images=10):
    import matplotlib.pyplot as plt
    import numpy as np

    for images, labels in dataset.take(1):
        preds = model.predict(images)
        preds_labels = np.argmax(preds, axis=1)
        plt.figure(figsize=(20, 6))
        for i in range(num_images):
            plt.subplot(2, 5, i+1)
            plt.imshow(images[i].numpy().astype("uint8"))
            true_label = class_names[labels[i].numpy()]
            pred_label = class_names[preds_labels[i]]
            color = "green" if true_label == pred_label else "red"
            plt.title(f"True: {true_label}\nPred: {pred_label}", color=color)
            plt.axis("off")
        plt.show()

# Usage:
visualize_predictions(model, test_ds_split, lesion_names, num_images=10)

# Save the complete model
model.save('my_model.h5')        # Saves as a single HDF5 file
# or
model.save('my_model.keras')     # Recommended newer format

# To load it later
from tensorflow.keras.models import load_model
model = load_model('my_model.h5')

from google.colab import drive
drive.mount('/content/drive')

# Save to your Drive
model.save('/content/drive/MyDrive/my_model.h5')

model.save('/content/drive/MyDrive/my_model.keras')

from tensorflow import keras

# Use model.export() to save in SavedModel format
model.export("my_model")

!zip -r my_model.zip my_model
from google.colab import files
files.download("my_model.zip")

!pip install tensorflow-addons

!pip install vit-keras

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, Input, Concatenate, GlobalAveragePooling2D, GlobalAveragePooling1D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
import vit_keras as vk
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

# Build ViT branch
def build_vit(input_shape=(224, 224, 3), num_classes=7):
    vit_model = vk.ViT(
        image_size=input_shape[0],
        pretrained=True,
        include_top=False,
        pretrained_top=False,
        activation=None
    )
    inputs = Input(shape=input_shape)
    x = vit_model(inputs)
    x = GlobalAveragePooling1D()(x)
    x = Dropout(0.3)(x)
    vit_output = Dense(512, activation='relu')(x)
    return inputs, vit_output

# Build hybrid model combining ResNet50 and ViT
def build_hybrid_model(input_shape=(224, 224, 3), num_classes=7):
    # ResNet50 branch
    base_resnet = tf.keras.applications.ResNet50(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    resnet_input = base_resnet.input
    x1 = base_resnet.output
    x1 = GlobalAveragePooling2D()(x1)
    x1 = Dropout(0.3)(x1)
    resnet_feat = Dense(512, activation='relu')(x1)

import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import (
    Dense, Dropout, GlobalAveragePooling2D,
    Concatenate, Flatten, MultiHeadAttention, LayerNormalization
)
from tensorflow.keras.optimizers import Adam

# --- Custom patch extraction layer ---
class PatchExtract(layers.Layer):
    def __init__(self, patch_size=16):
        super().__init__()
        self.patch_size = patch_size

    def build(self, input_shape):
        self.num_patches_x = input_shape[1] // self.patch_size
        self.num_patches_y = input_shape[2] // self.patch_size
        self.patch_dim = input_shape[3] * (self.patch_size ** 2)

    def call(self, images):
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding='VALID'
        )
        batch_size = tf.shape(images)[0]
        patches = tf.reshape(
            patches, [batch_size, self.num_patches_x * self.num_patches_y, self.patch_dim]
        )
        return patches

# --- ViT branch ---
def simple_vit_branch(input_shape=(224, 224, 3), patch_size=16, embed_dim=256, num_heads=4):
    vit_input = Input(shape=input_shape)
    x = PatchExtract(patch_size)(vit_input)
    x = Dense(embed_dim)(x)
    attn = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)
    x = LayerNormalization()(x + attn)
    x = Flatten()(x)
    vit_feat = Dense(512, activation='relu')(x)
    return vit_input, vit_feat

# --- ResNet branch ---
def resnet_branch(input_shape=(224, 224, 3)):
    base_resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)
    base_resnet.trainable = False
    resnet_input = base_resnet.input
    x = GlobalAveragePooling2D()(base_resnet.output)
    x = Dropout(0.3)(x)
    resnet_feat = Dense(512, activation='relu')(x)
    return resnet_input, resnet_feat

# --- Combine both branches ---
input_shape = (224, 224, 3)
num_classes = 7

resnet_input, resnet_feat = resnet_branch(input_shape)
vit_input, vit_feat = simple_vit_branch(input_shape)

# Concatenate features
combined = Concatenate()([resnet_feat, vit_feat])
x = Dropout(0.5)(combined)
x = Dense(256, activation='relu')(x)
output = Dense(num_classes, activation='softmax')(x)

# --- Build and compile hybrid model ---
model = Model(inputs=[resnet_input, vit_input], outputs=output)
model.compile(optimizer=Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Concatenate features
combined = Concatenate()([resnet_feat, vit_feat])
x = Dropout(0.5)(combined)
x = Dense(256, activation='relu')(x)
output = Dense(num_classes, activation='softmax')(x)

# Hybrid model with two inputs (same image input twice)
input_shape = (224, 224, 3)
num_classes = 7

model = build_hybrid_model(input_shape, num_classes)
model.summary()

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/MyDrive/hams"

import pandas as pd
import tensorflow as tf
import os
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# Paths
img_dir = "/content/drive/MyDrive/hams/all_images"
meta_csv = "/content/drive/MyDrive/hams/HAM10000_metadata.csv"

# Load metadata
df = pd.read_csv(meta_csv)

# Add .jpg extension if missing
df['image_id'] = df['image_id'].apply(lambda x: x + '.jpg')

# Full image paths
df['path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, x))

# Encode labels (diagnosis column)
label_names = df['dx'].unique()
label_map = {name: i for i, name in enumerate(label_names)}
df['label'] = df['dx'].map(label_map)

# Train-test split
train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)

# Image loader
def preprocess(path, label):
    img = tf.io.read_file(path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, (224, 224))
    img = img / 255.0
    return img, label

train_data = tf.data.Dataset.from_tensor_slices((train_df['path'], train_df['label'])).map(preprocess).batch(32)
val_data = tf.data.Dataset.from_tensor_slices((val_df['path'], val_df['label'])).map(preprocess).batch(32)

# Duplicate inputs for hybrid model (same image for both branches)
train_data = train_data.map(lambda x, y: ((x, x), y))
val_data = val_data.map(lambda x, y: ((x, x), y))

print("âœ… Dataset ready! Classes:", label_map)

# ðŸ”¹ Normalize both inputs (ResNet + ViT branches)
normalization_layer = tf.keras.layers.Rescaling(1./255)

train_data = train_data.map(
    lambda x, y: ((normalization_layer(x[0]), normalization_layer(x[1])), y)
)
val_data = val_data.map(
    lambda x, y: ((normalization_layer(x[0]), normalization_layer(x[1])), y)
)

print("âœ… Normalization applied successfully!")

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=25,
    callbacks=callbacks
)

# Load best weights
model.load_weights('best_hybrid_model.h5')

# Find and unfreeze the ResNet50 base
for layer in model.layers:
    if "resnet" in layer.name.lower():
        layer.trainable = True

# Or more selectively (last few ResNet layers)
for layer in model.layers[-30:]:
    layer.trainable = True

# Recompile with a smaller learning rate
from tensorflow.keras.optimizers import Adam
model.compile(optimizer=Adam(1e-5),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history2 = model.fit(
    train_data,
    validation_data=val_data,
    epochs=15,
    callbacks=callbacks
)

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend()
plt.title('Accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.title('Loss')

plt.show()

final_train_acc = history2.history['accuracy'][-1]
final_val_acc = history2.history['val_accuracy'][-1]

print(f"âœ… Final Training Accuracy: {final_train_acc*100:.2f}%")
print(f"âœ… Final Validation Accuracy (Main Accuracy): {final_val_acc*100:.2f}%")

# Save final model
model.save('my_hybrid_model.h5')
model.save('my_hybrid_model.keras')

model.save('/content/drive/MyDrive/my_hybrid_model.h5')
model.save('/content/drive/MyDrive/my_hybrid_model.keras')

!zip -r my_hybrid_model.zip my_hybrid_model

import os

# Create a folder for models in your Drive
os.makedirs('/content/drive/MyDrive/saved_models', exist_ok=True)

!zip -r /content/drive/MyDrive/saved_models/my_resnet_model.zip /content/drive/MyDrive/saved_models/my_resnet_model
!zip -r /content/drive/MyDrive/saved_models/my_hybrid_model.zip /content/drive/MyDrive/saved_models/my_hybrid_model

model.save("/content/final_hybrid_model.keras")

model.save("/content/final_hybrid_model.h5")

!zip -r /content/final_hybrid_model.zip /content/final_hybrid_model.keras

!zip -r /content/final_hybrid_model.zip /content/final_hybrid_model.h5

from google.colab import files
files.download("/content/final_hybrid_model.zip")

!cp /content/final_hybrid_model.zip "/content/drive/MyDrive/final_hybrid_model.zip"
print("âœ… Saved to Google Drive: MyDrive/final_hybrid_model.zip")